{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e557ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14eacd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_location</th>\n",
       "      <th>full_text</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Pos_VERB_count</th>\n",
       "      <th>Neg_VERB_count</th>\n",
       "      <th>Pos_ADV_count</th>\n",
       "      <th>Neg_ADV_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>weighted_compound</th>\n",
       "      <th>weighted_compound_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-06T17:30:21.000+05:30</td>\n",
       "      <td>1.103136e+18</td>\n",
       "      <td>2019-03-06T03:33:25.000+05:30</td>\n",
       "      <td>Guwahati</td>\n",
       "      <td>Guwahati has gained a lot of prominence in rec...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>73.2918</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-17T18:11:58.000+05:30</td>\n",
       "      <td>1.107333e+18</td>\n",
       "      <td>2019-03-17T17:27:57.000+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RSS in school days itself? Indoctrinated since...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.7906</td>\n",
       "      <td>-3.9530</td>\n",
       "      <td>-0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-23T18:07:38.000+05:30</td>\n",
       "      <td>1.109417e+18</td>\n",
       "      <td>2019-03-23T11:28:31.000+05:30</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Words don't exist in Vaccum!\\nModi's post Pulw...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6900</td>\n",
       "      <td>-21.3900</td>\n",
       "      <td>-0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-11T17:47:32.000+05:30</td>\n",
       "      <td>1.100300e+18</td>\n",
       "      <td>2019-02-26T07:40:28.000+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India's #Icecream Industry stands at 15,000 cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>-0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-02-27T18:18:42.000+05:30</td>\n",
       "      <td>1.100733e+18</td>\n",
       "      <td>2019-02-27T12:21:18.000+05:30</td>\n",
       "      <td>Delhi | Odisha</td>\n",
       "      <td>*40 CRPF Jawans killed in Pulwama Attack\\n*IAF...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9638</td>\n",
       "      <td>-8.6742</td>\n",
       "      <td>-0.000377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   last_updated      tweet_id  \\\n",
       "0           0  2019-03-06T17:30:21.000+05:30  1.103136e+18   \n",
       "1           1  2019-03-17T18:11:58.000+05:30  1.107333e+18   \n",
       "2           2  2019-03-23T18:07:38.000+05:30  1.109417e+18   \n",
       "3           3  2019-03-11T17:47:32.000+05:30  1.100300e+18   \n",
       "4           4  2019-02-27T18:18:42.000+05:30  1.100733e+18   \n",
       "\n",
       "                      created_at   user_location  \\\n",
       "0  2019-03-06T03:33:25.000+05:30       Guwahati    \n",
       "1  2019-03-17T17:27:57.000+05:30             NaN   \n",
       "2  2019-03-23T11:28:31.000+05:30      New Delhi    \n",
       "3  2019-02-26T07:40:28.000+05:30             NaN   \n",
       "4  2019-02-27T12:21:18.000+05:30  Delhi | Odisha   \n",
       "\n",
       "                                           full_text quote_count  reply_count  \\\n",
       "0  Guwahati has gained a lot of prominence in rec...           0          4.0   \n",
       "1  RSS in school days itself? Indoctrinated since...           0          0.0   \n",
       "2  Words don't exist in Vaccum!\\nModi's post Pulw...           0          4.0   \n",
       "3  India's #Icecream Industry stands at 15,000 cr...           0          0.0   \n",
       "4  *40 CRPF Jawans killed in Pulwama Attack\\n*IAF...           0          0.0   \n",
       "\n",
       "  retweet_count  favorite_count  ... Pos_VERB_count Neg_VERB_count  \\\n",
       "0         113.0           113.0  ...            0.0            0.0   \n",
       "1           5.0             5.0  ...            0.0            0.0   \n",
       "2          31.0            31.0  ...            0.0            0.0   \n",
       "3           3.0             3.0  ...            0.0            0.0   \n",
       "4           9.0             9.0  ...            0.0            0.0   \n",
       "\n",
       "  Pos_ADV_count Neg_ADV_count    neg    neu    pos compound weighted_compound  \\\n",
       "0           0.0           0.0  0.000  0.880  0.120   0.6486           73.2918   \n",
       "1           0.0           0.0  0.332  0.579  0.088  -0.7906           -3.9530   \n",
       "2           0.0           0.0  0.130  0.870  0.000  -0.6900          -21.3900   \n",
       "3           0.0           0.0  0.000  0.955  0.045   0.1779            0.5337   \n",
       "4           0.0           0.0  0.362  0.638  0.000  -0.9638           -8.6742   \n",
       "\n",
       "  weighted_compound_new  \n",
       "0              0.000911  \n",
       "1             -0.000303  \n",
       "2             -0.000577  \n",
       "3             -0.000232  \n",
       "4             -0.000377  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read csv file\n",
    "df=pd.read_csv('political_tweets.csv',delimiter='|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64bd342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46043, 44)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877e158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                       0\n",
       "last_updated                     0\n",
       "tweet_id                         2\n",
       "created_at                       2\n",
       "user_location                 5779\n",
       "full_text                        2\n",
       "quote_count                   1402\n",
       "reply_count                   1410\n",
       "retweet_count                    7\n",
       "favorite_count                   0\n",
       "hashtags                     36836\n",
       "user_mentions_screen_name    28320\n",
       "OfImportance                     7\n",
       "subject                          7\n",
       "ADJ                              7\n",
       "NOUN                             7\n",
       "VERB                             7\n",
       "ADV                              7\n",
       "Pos_ADJ                          7\n",
       "Neg_ADJ                          7\n",
       "Pos_NOUN                         7\n",
       "Neg_NOUN                         7\n",
       "Pos_VERB                         8\n",
       "Neg_VERB                         8\n",
       "Pos_ADV                         12\n",
       "Neg_ADV                          8\n",
       "City                         30330\n",
       "State                        28788\n",
       "District                     46038\n",
       "Country                      20700\n",
       "Pos_ADJ_count                    7\n",
       "Neg_ADJ_count                    7\n",
       "Pos_NOUN_count                   7\n",
       "Neg_NOUN_count                   7\n",
       "Pos_VERB_count                   7\n",
       "Neg_VERB_count                   7\n",
       "Pos_ADV_count                    7\n",
       "Neg_ADV_count                    7\n",
       "neg                              7\n",
       "neu                              7\n",
       "pos                             12\n",
       "compound                        12\n",
       "weighted_compound               12\n",
       "weighted_compound_new           12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of null value in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156947cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the missing value with empty string\n",
    "df['hashtags']=df[['hashtags']].fillna('')\n",
    "df['user_location']=df[['user_location']].fillna('')\n",
    "df['full_text']=df[['full_text']].fillna('')\n",
    "df['subject']=df[['subject']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9307393f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                       0\n",
       "last_updated                     0\n",
       "tweet_id                         2\n",
       "created_at                       2\n",
       "user_location                    0\n",
       "full_text                        0\n",
       "quote_count                   1402\n",
       "reply_count                   1410\n",
       "retweet_count                    7\n",
       "favorite_count                   0\n",
       "hashtags                         0\n",
       "user_mentions_screen_name    28320\n",
       "OfImportance                     7\n",
       "subject                          0\n",
       "ADJ                              7\n",
       "NOUN                             7\n",
       "VERB                             7\n",
       "ADV                              7\n",
       "Pos_ADJ                          7\n",
       "Neg_ADJ                          7\n",
       "Pos_NOUN                         7\n",
       "Neg_NOUN                         7\n",
       "Pos_VERB                         8\n",
       "Neg_VERB                         8\n",
       "Pos_ADV                         12\n",
       "Neg_ADV                          8\n",
       "City                         30330\n",
       "State                        28788\n",
       "District                     46038\n",
       "Country                      20700\n",
       "Pos_ADJ_count                    7\n",
       "Neg_ADJ_count                    7\n",
       "Pos_NOUN_count                   7\n",
       "Neg_NOUN_count                   7\n",
       "Pos_VERB_count                   7\n",
       "Neg_VERB_count                   7\n",
       "Pos_ADV_count                    7\n",
       "Neg_ADV_count                    7\n",
       "neg                              7\n",
       "neu                              7\n",
       "pos                             12\n",
       "compound                        12\n",
       "weighted_compound               12\n",
       "weighted_compound_new           12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of missing value in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a673b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guwahati has gained a lot of prominence in rec...</td>\n",
       "      <td>Bjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RSS in school days itself? Indoctrinated since...</td>\n",
       "      <td>Bjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Words don't exist in Vaccum!\\nModi's post Pulw...</td>\n",
       "      <td>Bjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India's #Icecream Industry stands at 15,000 cr...</td>\n",
       "      <td>Congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*40 CRPF Jawans killed in Pulwama Attack\\n*IAF...</td>\n",
       "      <td>Bjp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text   subject\n",
       "0  Guwahati has gained a lot of prominence in rec...       Bjp\n",
       "1  RSS in school days itself? Indoctrinated since...       Bjp\n",
       "2  Words don't exist in Vaccum!\\nModi's post Pulw...       Bjp\n",
       "3  India's #Icecream Industry stands at 15,000 cr...  Congress\n",
       "4  *40 CRPF Jawans killed in Pulwama Attack\\n*IAF...       Bjp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['full_text','subject']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3112dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e464125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca2befc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8d0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the text\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopwords]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "\n",
    "df[\"full_text\"] = df[\"full_text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07220ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.full_text, \n",
    "    df.subject, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "703e9576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (36834,)\n",
      "Shape of X_test:  (9209,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c738fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85722fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               Bjp       0.76      0.98      0.85      4934\n",
      "          Congress       0.95      0.69      0.80      3905\n",
      "            Others       0.00      0.00      0.00       369\n",
      "['not', 'instead']       0.00      0.00      0.00         1\n",
      "\n",
      "          accuracy                           0.82      9209\n",
      "         macro avg       0.43      0.42      0.41      9209\n",
      "      weighted avg       0.81      0.82      0.79      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a29b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "                         0.00      0.00      0.00         0\n",
      "               Bjp       0.95      0.99      0.97      4934\n",
      "          Congress       0.98      0.95      0.97      3905\n",
      "            Others       1.00      0.76      0.86       369\n",
      "['not', 'instead']       0.00      0.00      0.00         1\n",
      "\n",
      "          accuracy                           0.96      9209\n",
      "         macro avg       0.59      0.54      0.56      9209\n",
      "      weighted avg       0.97      0.96      0.96      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f0915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               Bjp       0.95      0.98      0.96      4934\n",
      "          Congress       0.97      0.95      0.96      3905\n",
      "            Others       1.00      0.77      0.87       369\n",
      "['not', 'instead']       0.00      0.00      0.00         1\n",
      "\n",
      "          accuracy                           0.96      9209\n",
      "         macro avg       0.73      0.68      0.70      9209\n",
      "      weighted avg       0.96      0.96      0.96      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('Logistic Regression', LogisticRegression())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('SVC', SVC())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02693bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               Bjp       0.95      0.97      0.96      4934\n",
      "          Congress       0.96      0.95      0.96      3905\n",
      "            Others       1.00      0.80      0.89       369\n",
      "['not', 'instead']       0.00      0.00      0.00         1\n",
      "\n",
      "          accuracy                           0.96      9209\n",
      "         macro avg       0.73      0.68      0.70      9209\n",
      "      weighted avg       0.96      0.96      0.96      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('SGDClassifier', SGDClassifier(loss = 'hinge', penalty = 'l2', random_state=42))         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1b93dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model for senmtiment ie pos,neg,neu\n",
    "new_data=df[['full_text']]\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90306e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "new_data['sentiment'] = new_data['full_text'].apply(lambda x: sid.polarity_scores(x))\n",
    "\n",
    "def sentimentVerdict(sentiment):\n",
    "  if sentiment['compound'] >= 0.05:\n",
    "    return \"Positive\"\n",
    "  elif sentiment['compound'] <= -0.05:\n",
    "    return \"Negative\"\n",
    "  else:\n",
    "    return \"Neutral\"\n",
    "\n",
    "new_data['sentiment_overall'] = new_data['sentiment'].apply(lambda x: sentimentVerdict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da9a7a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guwahati gain lot promin recent year due pm sh...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.816, 'pos': 0.184, 'comp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rss school day indoctrin sinc childhood thrice...</td>\n",
       "      <td>{'neg': 0.421, 'neu': 0.458, 'pos': 0.121, 'co...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word dont exist vaccummodi post pulwama word g...</td>\n",
       "      <td>{'neg': 0.114, 'neu': 0.886, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india icecream industri stand  crore fastest g...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crpf jawan kill pulwama attackiaf strike paki...</td>\n",
       "      <td>{'neg': 0.396, 'neu': 0.604, 'pos': 0.0, 'comp...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  guwahati gain lot promin recent year due pm sh...   \n",
       "1  rss school day indoctrin sinc childhood thrice...   \n",
       "2  word dont exist vaccummodi post pulwama word g...   \n",
       "3  india icecream industri stand  crore fastest g...   \n",
       "4   crpf jawan kill pulwama attackiaf strike paki...   \n",
       "\n",
       "                                           sentiment sentiment_overall  \n",
       "0  {'neg': 0.0, 'neu': 0.816, 'pos': 0.184, 'comp...          Positive  \n",
       "1  {'neg': 0.421, 'neu': 0.458, 'pos': 0.121, 'co...          Negative  \n",
       "2  {'neg': 0.114, 'neu': 0.886, 'pos': 0.0, 'comp...          Negative  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...           Neutral  \n",
       "4  {'neg': 0.396, 'neu': 0.604, 'pos': 0.0, 'comp...          Negative  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48d236ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guwahati gain lot promin recent year due pm sh...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rss school day indoctrin sinc childhood thrice...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word dont exist vaccummodi post pulwama word g...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india icecream industri stand  crore fastest g...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crpf jawan kill pulwama attackiaf strike paki...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text sentiment_overall\n",
       "0  guwahati gain lot promin recent year due pm sh...          Positive\n",
       "1  rss school day indoctrin sinc childhood thrice...          Negative\n",
       "2  word dont exist vaccummodi post pulwama word g...          Negative\n",
       "3  india icecream industri stand  crore fastest g...           Neutral\n",
       "4   crpf jawan kill pulwama attackiaf strike paki...          Negative"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data=new_data[['full_text','sentiment_overall']]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b77ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    new_data.full_text, \n",
    "    new_data.sentiment_overall, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0754badd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.66      0.79      0.72      3144\n",
      "     Neutral       0.94      0.15      0.25      2520\n",
      "    Positive       0.59      0.84      0.69      3545\n",
      "\n",
      "    accuracy                           0.63      9209\n",
      "   macro avg       0.73      0.59      0.56      9209\n",
      "weighted avg       0.71      0.63      0.58      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8705083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.80      0.82      3144\n",
      "     Neutral       0.83      0.91      0.87      2520\n",
      "    Positive       0.85      0.85      0.85      3545\n",
      "\n",
      "    accuracy                           0.85      9209\n",
      "   macro avg       0.85      0.85      0.85      9209\n",
      "weighted avg       0.85      0.85      0.85      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cce4159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.83      0.84      3144\n",
      "     Neutral       0.82      0.89      0.85      2520\n",
      "    Positive       0.88      0.86      0.87      3545\n",
      "\n",
      "    accuracy                           0.86      9209\n",
      "   macro avg       0.85      0.86      0.86      9209\n",
      "weighted avg       0.86      0.86      0.86      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('Logistic Regression', LogisticRegression())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de642707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.82      0.84      3144\n",
      "     Neutral       0.80      0.90      0.85      2520\n",
      "    Positive       0.88      0.84      0.86      3545\n",
      "\n",
      "    accuracy                           0.85      9209\n",
      "   macro avg       0.85      0.85      0.85      9209\n",
      "weighted avg       0.85      0.85      0.85      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('SVC', SVC())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ee0c81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.82      0.84      3144\n",
      "     Neutral       0.81      0.89      0.85      2520\n",
      "    Positive       0.87      0.85      0.86      3545\n",
      "\n",
      "    accuracy                           0.85      9209\n",
      "   macro avg       0.85      0.85      0.85      9209\n",
      "weighted avg       0.85      0.85      0.85      9209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('SGDClassifier', SGDClassifier(loss = 'hinge', penalty = 'l2', random_state=42))         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d7990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
